{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "57fa7f76-e629-42cb-ac0b-5256f6c7dda2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql import Window\n",
    "from pyspark.sql.types import StructType, StringType, IntegerType, DoubleType, StructField,TimestampType\n",
    "import redis\n",
    "import json\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "79800bfe-a760-4762-b3a2-e342e9874423",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "base_connection_string = os.getenv(\"EVENT_HUB_CONNECTION_STR\")\n",
    "\n",
    "entity_paths = ['raw_glucose_readings', 'raw_device_feeds'] # # Initializing Connection String for incoming raw glucose readings\n",
    "entity_paths_target = ['above_max_glucose_threshold', 'below_min_glucose_threshold' ,'missed_readings', 'device_error'] # Sending Data To This Ones\n",
    "\n",
    "configs = {}\n",
    "\n",
    "# Encrypting the connection string with the entity path\n",
    "for entity_path in entity_paths + entity_paths_target:\n",
    "    entity_conn_string = f\"{base_connection_string};EntityPath={entity_path}\"\n",
    "    encrypted_conn_string = spark._jvm.org.apache.spark.eventhubs.EventHubsUtils.encrypt(entity_conn_string)\n",
    "    configs[entity_path] = {\n",
    "        \"eventhubs.connectionString\": encrypted_conn_string\n",
    "    }\n",
    "    if entity_path in entity_paths:\n",
    "        configs[entity_path][\"eventhubs.consumerGroup\"] = \"spark\"\n",
    "\n",
    "# Accessing the configurations\n",
    "ehConfGlucose = configs['raw_glucose_readings']\n",
    "ehConfDevice = configs['raw_device_feeds']\n",
    "ehConfHighGlucose = configs['above_max_glucose_threshold']\n",
    "ehConfigLowGlucose=configs['below_min_glucose_threshold']\n",
    "ehConfMS = configs['missed_readings']\n",
    "ehConfLostConn=configs['device_error']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1017aea6-a51a-40d9-a225-f8f691cb8a20",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class RedisConnection:\n",
    "    \"\"\"\n",
    "    A class representing a Redis connection.\n",
    "\n",
    "    This class provides a static method to get a singleton instance of a Redis connection.\n",
    "\n",
    "    Attributes:\n",
    "        _instance: The singleton instance of the Redis connection.\n",
    "\n",
    "    Methods:\n",
    "        get_instance: Returns the singleton instance of the Redis connection.\n",
    "    \"\"\"\n",
    "    \n",
    "    _instance = None\n",
    "\n",
    "    @staticmethod\n",
    "    def get_instance(host, port, password):\n",
    "        \"\"\"\n",
    "        Returns the singleton instance of the Redis connection.\n",
    "\n",
    "        Args:\n",
    "            host: The host for the Redis connection.\n",
    "            port: The port for the Redis connection.\n",
    "            password: The password for the Redis connection.\n",
    "\n",
    "        Returns:\n",
    "            The singleton instance of the Redis connection.\n",
    "        \"\"\"\n",
    "        if RedisConnection._instance is None:\n",
    "            RedisConnection._instance = redis.Redis(\n",
    "                host=host,\n",
    "                port=port,\n",
    "                password=password,\n",
    "                ssl=True,\n",
    "                decode_responses=True\n",
    "            )\n",
    "        return RedisConnection._instance\n",
    "\n",
    "def get_redis_connection():\n",
    "    \"\"\"\n",
    "    Returns a Redis connection instance.\n",
    "    \"\"\"\n",
    "    return RedisConnection.get_instance(\n",
    "        os.getenv('REDIS_HOST_NAME'),\n",
    "        int(os.getenv('REDIS_SSL_PORT')),\n",
    "        os.getenv('REDIS_PRIMARY_ACCESS_KEY')\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d29d08c2-75d3-4e5b-ac0d-4655e2c8cdb2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"EventHubGlucoseReadings\").getOrCreate()\n",
    "\n",
    "# Optimizing shuffle partitions since I am performing some joins in this notebook\n",
    "spark.conf.set(\"spark.sql.shuffle.partitions\", \"4\")  \n",
    "\n",
    "# For ignoring empty micro-batches\n",
    "spark.conf.set(\"spark.sql.streaming.noDataMicroBatches.enabled\", \"true\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4b58e558-3015-4133-82ea-f6740441b643",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def fetch_patient_details(user_id):\n",
    "    try:\n",
    "        r = get_redis_connection()\n",
    "        data = r.hgetall(f\"user:{user_id}\")\n",
    "        print(f\"Fetched data for user_id {user_id}: {data}\")\n",
    "        return json.dumps(data)\n",
    "    except Exception as e:\n",
    "        return json.dumps({\"error\": str(e)})\n",
    "\n",
    "def fetch_device_details(device_id):\n",
    "    try:\n",
    "        r = get_redis_connection()\n",
    "        data = r.hgetall(f\"device:{device_id}\")\n",
    "        print(f\"Fetched data for device_id {device_id}: {data}\")\n",
    "        return json.dumps(data)\n",
    "    except Exception as e:\n",
    "        return json.dumps({\"error\": str(e)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "52e7b814-2636-46f3-849a-fbd734f6b8c2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Schema for raw_glucose_readings\n",
    "glucose_schema = StructType() \\\n",
    "    .add(\"user_id\", IntegerType()) \\\n",
    "    .add(\"device_id\", IntegerType()) \\\n",
    "    .add(\"timestamp\", StringType()) \\\n",
    "    .add(\"glucose_reading\", DoubleType()) \\\n",
    "    .add(\"latitude\", DoubleType()) \\\n",
    "    .add(\"longitude\", DoubleType())\n",
    "\n",
    "\n",
    "#Schema Patient Details\n",
    "patient_schema = StructType([\n",
    "    StructField(\"patient_name\", StringType()),\n",
    "    StructField(\"patient_age\", StringType()), \n",
    "    StructField(\"gender\", StringType()),\n",
    "    StructField(\"min_glucose\", StringType()), # Minimum level at which glucose should be\n",
    "    StructField(\"max_glucose\", StringType()), # Maximum it should be at\n",
    "    StructField(\"medical_condition\", StringType()),\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5361a176-9939-4f17-9a62-17b56a3264e2",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Schema for raw_device_feeds\n",
    "device_feed_schema = StructType() \\\n",
    "    .add(\"device_id\", IntegerType()) \\\n",
    "    .add(\"battery_level\", IntegerType()) \\\n",
    "    .add(\"firmware_name\", StringType()) \\\n",
    "    .add(\"firmware_version\", StringType()) \\\n",
    "    .add(\"connection_status\", StringType()) \\\n",
    "    .add(\"error_code\", StringType()) \\\n",
    "    .add(\"timestamp\", StringType())\n",
    "\n",
    "\n",
    "#Schema Device Details\n",
    "device_schema = StructType([\n",
    "    StructField(\"owner_name\", StringType()),\n",
    "    StructField(\"device_model\", StringType()), \n",
    "    StructField(\"data_transmission_interval\", StringType()), ## RATE AT WHICH DEVICE IS EXPECTED TO SEND INFORMATION RELATED TO THE USER GLUCOSE LEVEL\n",
    "    StructField(\"expected_transmissions\", StringType()),  ## expected_transmissions IS CALCULATED FROM data_transmission_interval for 15 minutes window time\n",
    "    StructField(\"manufacturer_name\", StringType()), \n",
    "])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2af696dc-4bd5-4c35-873e-eed3564383b6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Read from the Event Hub\n",
    "glucose_readings_df = spark \\\n",
    "  .readStream \\\n",
    "  .format(\"eventhubs\") \\\n",
    "  .options(**ehConfGlucose) \\\n",
    "  .load() \\\n",
    "  .select(from_json(col(\"body\").cast(\"string\"), glucose_schema).alias(\"data\")) \\\n",
    "  .select(\n",
    "      col(\"data.user_id\"),\n",
    "      col(\"data.device_id\"),\n",
    "      to_timestamp('data.timestamp', \"yyyy-MM-dd'T'HH:mm:ss\").alias('timestamp'),\n",
    "      col(\"data.glucose_reading\"),\n",
    "      col(\"data.latitude\"),\n",
    "      col(\"data.longitude\")\n",
    "  )\n",
    "\n",
    "fetch_patient_udf = udf(fetch_patient_details, StringType())\n",
    "\n",
    "enriched_df = glucose_readings_df.withColumn(\"patient_details_json\", fetch_patient_udf(col(\"user_id\")))\n",
    "\n",
    "# Parse JSON string into separate columns\n",
    "enriched_df = enriched_df.withColumn(\"patient_details\", from_json(col(\"patient_details_json\"), patient_schema))\n",
    "enriched_df = enriched_df.select(\"*\", \"patient_details.*\")\n",
    "enriched_df = enriched_df.withColumn(\"max_glucose\", col(\"patient_details.max_glucose\").cast(IntegerType()))\n",
    "enriched_df = enriched_df.withColumn(\"min_glucose\", col(\"patient_details.min_glucose\").cast(IntegerType()))\n",
    "# enriched_df = enriched_df.withColumn(\"num_readings_required\", col(\"patient_details.num_readings_required\").cast(IntegerType()))\n",
    "\n",
    "enriched_df = enriched_df.withColumn(\"reading_over_max_glucose\", when(col(\"glucose_reading\") > col(\"max_glucose\"), 1).otherwise(0))\n",
    "enriched_df = enriched_df.withColumn(\"reading_over_min_glucose\", when(col(\"glucose_reading\") < col(\"min_glucose\"), 1).otherwise(0))\n",
    "\n",
    "\n",
    "final_df = enriched_df.select(\n",
    "    col(\"user_id\"),\n",
    "    col(\"device_id\"),\n",
    "    col(\"timestamp\"),\n",
    "    col('glucose_reading'),\n",
    "    col('latitude'),\n",
    "    col('longitude'),\n",
    "    col(\"patient_details.patient_name\").alias(\"patient_name\"),\n",
    "    col(\"patient_details.patient_age\").alias(\"patient_age\"),\n",
    "    col(\"patient_details.gender\").alias(\"gender\"),\n",
    "    col(\"max_glucose\"),  \n",
    "    col(\"min_glucose\"),\n",
    "    col(\"patient_details.medical_condition\").alias(\"medical_condition\"),  \n",
    "    col(\"reading_over_max_glucose\"),\n",
    "    col(\"reading_over_min_glucose\")\n",
    ")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "24bd7ecf-0617-4041-92e9-c5898170af8d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "device_feeds_df = spark \\\n",
    "  .readStream \\\n",
    "  .format(\"eventhubs\") \\\n",
    "  .options(**ehConfDevice) \\\n",
    "  .load() \\\n",
    "  .select(from_json(col(\"body\").cast(\"string\"), device_feed_schema).alias(\"data\")) \\\n",
    "  .select(\n",
    "      col(\"data.device_id\"),\n",
    "      col(\"data.battery_level\"),\n",
    "      col(\"data.firmware_name\"),\n",
    "      col(\"data.firmware_version\"),\n",
    "      col(\"data.connection_status\"),\n",
    "      col(\"data.error_code\"),\n",
    "      to_timestamp('data.timestamp', \"yyyy-MM-dd'T'HH:mm:ss\").alias('timestamp')\n",
    "  )\n",
    "\n",
    "\n",
    "fetch_device_udf = udf(fetch_device_details, StringType())\n",
    "\n",
    "enriched_df = device_feeds_df.withColumn(\"device_details_json\", fetch_device_udf(col(\"device_id\")))\n",
    "\n",
    "# Parse JSON string into separate columns\n",
    "enriched_df = enriched_df.withColumn(\"device_details\", from_json(col(\"device_details_json\"), device_schema))\n",
    "enriched_df = enriched_df.select(\"*\", \"device_details.*\")\n",
    "enriched_df = enriched_df.withColumn(\"data_transmission_interval\", col(\"device_details.data_transmission_interval\").cast(IntegerType()))\n",
    "enriched_df = enriched_df.withColumn(\"expected_transmissions\", col(\"device_details.expected_transmissions\").cast(IntegerType()))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "final_device_df = enriched_df.select(\n",
    "    col(\"device_id\"),\n",
    "    col(\"timestamp\"),\n",
    "    col('battery_level'),\n",
    "    col('firmware_name'),\n",
    "    col('firmware_version'),\n",
    "    col('connection_status'),\n",
    "    col('error_code'),\n",
    "    col(\"device_details.owner_name\").alias(\"owner_name\"),\n",
    "    col(\"device_details.device_model\").alias(\"device_model\"),\n",
    "    col(\"device_details.data_transmission_interval\").alias(\"data_transmission_interval\"),\n",
    "    col(\"device_details.expected_transmissions\").alias(\"expected_transmissions\"),\n",
    "    col(\"device_details.manufacturer_name\").alias(\"manufacturer_name\")\n",
    ") \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ee511c61-94e6-4891-9848-ac185e5f8b15",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "## Joining both dataframes for a business logic\n",
    "final_df = final_df.withColumnRenamed(\"timestamp\", \"final_df_timestamp\")\n",
    "combined_df = final_df.join(final_device_df, on=['device_id'])\n",
    "\n",
    "combined_feeds_df = combined_df.select(\n",
    "    col(\"device_id\"),\n",
    "    col('device_model'),\n",
    "    col('user_id'),\n",
    "    col('patient_name'),\n",
    "    col('glucose_reading'),\n",
    "    col('data_transmission_interval'),\n",
    "    col('expected_transmissions'),  \n",
    "    col(\"final_df_timestamp\")\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "90a801e1-2d5f-480a-b76e-aa284f574f86",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "EVERY DEVICE HAS A RATE AT WHICH IT EXPECTED TO SEND UPDATES ON GLUCOSE LEVEL. FOR EXAMPLE, a data_transmission_interval OF 2 MEANS THAT EVERY 2 MINUTES,\n",
    "AN UPDATE ABOUT THE USER'S GLUCOSE LEVEL IS TRANSMITTED. THE COLUMN expected_transmissions WAS CALCULATED FOR EVERY DEVICE FOR A 15 MINUTES WINDOW BEFORE BEIGN SENT TO REDIS. \n",
    "\n",
    "BELOW, THE CODE BLOCK CREATES A 15 MINUTES WINDOW WHERE INCOMING GLUCOSE READINGS ARE COUNTED AND AT THE END WILL BE COMPARED TO expected_transmissions.\n",
    "THIS CAN HELP INVESTIGATE AS TO IF THE DEVICES ARE WELL CALIBRATED AND SEND UPDATES ABOUT THE USERS AT THE EXPECTED RATE. OR, MORE INQUIRIES ABOUT THE QUALITY OF THE DEVICE, DISCONNECTIONS OR IF SOME USERS MIGHT BE NEGLECTING WEARING THE DEVICE. \n",
    "\"\"\"\n",
    "\n",
    "\n",
    "result_df = combined_feeds_df \\\n",
    "    .withWatermark(\"final_df_timestamp\", \"1 minute\") \\\n",
    "    .groupBy(window(col('final_df_timestamp'), \"15 minutes\"), col('user_id'),col('patient_name'),col('device_id'),col(\"device_model\"),col('expected_transmissions'),) \\\n",
    "    .agg(count(\"*\").alias(\"count_transmissions\")) \\\n",
    "    .filter(col(\"count_transmissions\") < col(\"expected_transmissions\"))\n",
    "\n",
    "\n",
    "result_df = result_df.select(\n",
    "    col(\"window\").start.alias(\"window_start\"),\n",
    "    col(\"window\").end.alias(\"window_end\"),\n",
    "    col('user_id'),\n",
    "    col(\"patient_name\"),\n",
    "    col('device_id'),\n",
    "    col(\"device_model\"),\n",
    "    col('expected_transmissions'),\n",
    "    col('count_transmissions')\n",
    ")\n",
    "\n",
    "missed_readings_df = result_df.select(\n",
    "    col(\"user_id\").cast(\"string\").alias(\"partitionKey\"),\n",
    "    to_json(struct([result_df[x] for x in result_df.columns])).alias(\"body\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "841ff860-c1b6-4e24-90eb-18751aa6dc35",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Filtering for glucose_reading above max_treshold\n",
    "high_glucose_df = final_df.select(\n",
    "    col(\"user_id\"),\n",
    "    col(\"device_id\"),\n",
    "    col('patient_name'),\n",
    "    col(\"final_df_timestamp\"),\n",
    "    col('glucose_reading'),\n",
    "    col(\"max_glucose\"))\\\n",
    "    .filter(\"reading_over_max_glucose==1\")\n",
    "\n",
    "\n",
    "high_glucose_json_df = high_glucose_df.select(\n",
    "    col(\"user_id\").cast(\"string\").alias(\"partitionKey\"),\n",
    "    to_json(struct(*[col(x) for x in high_glucose_df.columns])).alias(\"body\")\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a1cdb662-3ff7-40f8-87f2-ceb3402535cd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Filtering for glucose_reading below min_treshold\n",
    "low_glucose_df = final_df.select(\n",
    "    col(\"user_id\"),\n",
    "    col(\"device_id\"),\n",
    "    col('patient_name'),\n",
    "    col(\"final_df_timestamp\"),\n",
    "    col('glucose_reading'),\n",
    "    col(\"min_glucose\"))\\\n",
    "    .filter(\"reading_over_min_glucose==1\")\n",
    "\n",
    "\n",
    "low_glucose_json_df = low_glucose_df.select(\n",
    "    col(\"user_id\").cast(\"string\").alias(\"partitionKey\"),\n",
    "    to_json(struct(*[col(x) for x in low_glucose_df.columns])).alias(\"body\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "99016927-4283-44ca-bac6-2da1b19c6206",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# spark.conf.set(\"spark.sql.streaming.statefulOperator.checkCorrectness.enabled\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "30d56190-7fc5-4613-9b13-b3c66b8de34a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Filtering for Devices were connection was lost\n",
    "\n",
    "lost_connection_df= final_device_df.select(\n",
    "    col(\"device_id\"),\n",
    "    col(\"timestamp\"),\n",
    "    col('battery_level'),\n",
    "    col('connection_status'),\n",
    "    col('error_code'),\n",
    "    col(\"owner_name\"),\n",
    "    col(\"manufacturer_name\")) \\\n",
    "        .filter(\"connection_status = 'Disconnected'\")\n",
    "\n",
    "lost_connection_json_df = lost_connection_df.select(\n",
    "    col(\"device_id\").cast(\"string\").alias(\"partitionKey\"),\n",
    "    to_json(struct(*[col(x) for x in lost_connection_df.columns])).alias(\"body\")\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "960144ec-ef90-4709-8e97-b4d65551d59a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint location deleted at /FileStore/tables/streaming-data/high-glucose-checkpoint-location\nCheckpoint location deleted at /FileStore/tables/streaming-data/low-glucose-checkpoint-location\nCheckpoint location deleted at /FileStore/tables/streaming-data/lost-connection-checkpoint-location\nCheckpoint location deleted at /FileStore/tables/streaming-data/transmission-quality-checkpoint-location\n"
     ]
    }
   ],
   "source": [
    "# List of checkpoint locations where the checkpoints will be stored during the streaming process\n",
    "# For Fault Tolerance and to ensure that the data is not lost during the streaming process\n",
    "checkpoint_high_glucose = \"/FileStore/tables/streaming-data/high-glucose-checkpoint-location\"\n",
    "checkpoint_low_glucose = \"/FileStore/tables/streaming-data/low-glucose-checkpoint-location\"\n",
    "checkpoint_lost_connection = \"/FileStore/tables/streaming-data/lost-connection-checkpoint-location\"\n",
    "checkpoint_transmission_quality = \"/FileStore/tables/streaming-data/transmission-quality-checkpoint-location\"\n",
    "\n",
    "checkpoint_list = [checkpoint_high_glucose, checkpoint_low_glucose, checkpoint_lost_connection, checkpoint_transmission_quality]\n",
    "\n",
    "def create_checkpoint_location(checkpoint_list):\n",
    "    for checkpoint in checkpoint_list:\n",
    "        try:\n",
    "            # We check if the directory exists\n",
    "            dbutils.fs.ls(checkpoint)\n",
    "            print(f\"Checkpoint location already exists at {checkpoint}\")\n",
    "        except Exception as e:\n",
    "            # The java.io error is returned when the directory does not exits\n",
    "            if \"java.io.FileNotFoundException\" in str(e):\n",
    "                # Directory doesn't exist, so create it\n",
    "                dbutils.fs.mkdirs(checkpoint)\n",
    "                print(f\"Checkpoint location created at {checkpoint}\")\n",
    "            else:\n",
    "                print(f\"Error processing {checkpoint}: {str(e)}\")\n",
    "\n",
    "# In case of wanting to restart.\n",
    "def delete_checkpoint_locations(checkpoint_list):\n",
    "    for checkpoint in checkpoint_list:\n",
    "        try:\n",
    "            \n",
    "            dbutils.fs.ls(checkpoint)\n",
    "            \n",
    "            dbutils.fs.rm(checkpoint, recurse=True)\n",
    "            print(f\"Checkpoint location deleted at {checkpoint}\")\n",
    "        except Exception as e:\n",
    "            # The java.io error is returned when the directory does not exist\n",
    "            if \"java.io.FileNotFoundException\" in str(e):\n",
    "                print(f\"Checkpoint location does not exist at {checkpoint}\")\n",
    "            else:\n",
    "                print(f\"Error processing {checkpoint}: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d44d2ae3-21e2-46c1-a3b2-312ae6b1182d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint location created at /FileStore/tables/streaming-data/high-glucose-checkpoint-location\nCheckpoint location created at /FileStore/tables/streaming-data/low-glucose-checkpoint-location\nCheckpoint location created at /FileStore/tables/streaming-data/lost-connection-checkpoint-location\nCheckpoint location created at /FileStore/tables/streaming-data/transmission-quality-checkpoint-location\n"
     ]
    }
   ],
   "source": [
    "# Creating Checkpoint Locations\n",
    "create_checkpoint_location(checkpoint_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "16dc33b0-8311-4591-9e55-0c5e9b8d4aa4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th><th>modificationTime</th></tr></thead><tbody><tr><td>dbfs:/FileStore/tables/streaming-data/high-glucose-checkpoint-location/</td><td>high-glucose-checkpoint-location/</td><td>0</td><td>1720369904000</td></tr><tr><td>dbfs:/FileStore/tables/streaming-data/lost-connection-checkpoint-location/</td><td>lost-connection-checkpoint-location/</td><td>0</td><td>1720369904000</td></tr><tr><td>dbfs:/FileStore/tables/streaming-data/low-glucose-checkpoint-location/</td><td>low-glucose-checkpoint-location/</td><td>0</td><td>1720369904000</td></tr><tr><td>dbfs:/FileStore/tables/streaming-data/transmission-quality-checkpoint-location/</td><td>transmission-quality-checkpoint-location/</td><td>0</td><td>1720369905000</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "dbfs:/FileStore/tables/streaming-data/high-glucose-checkpoint-location/",
         "high-glucose-checkpoint-location/",
         0,
         1720369904000
        ],
        [
         "dbfs:/FileStore/tables/streaming-data/lost-connection-checkpoint-location/",
         "lost-connection-checkpoint-location/",
         0,
         1720369904000
        ],
        [
         "dbfs:/FileStore/tables/streaming-data/low-glucose-checkpoint-location/",
         "low-glucose-checkpoint-location/",
         0,
         1720369904000
        ],
        [
         "dbfs:/FileStore/tables/streaming-data/transmission-quality-checkpoint-location/",
         "transmission-quality-checkpoint-location/",
         0,
         1720369905000
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "path",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "size",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "modificationTime",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# List contents of the /FileStore/tables/streaming-data directory\n",
    "display(dbutils.fs.ls(\"/FileStore/tables/streaming-data/\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "69bdbaaf-222c-473f-9c45-58db9f91aac9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Starting the different streaming Queries\n",
    "\n",
    "query = final_df.writeStream \\\n",
    "    .outputMode(\"append\") \\\n",
    "    .format(\"memory\") \\\n",
    "    .queryName(\"final_table\") \\\n",
    "    .start()\n",
    "\n",
    "query_high_glucose = high_glucose_json_df.writeStream \\\n",
    "    .format(\"eventhubs\") \\\n",
    "    .options(**ehConfHighGlucose) \\\n",
    "    .option(\"checkpointLocation\", checkpoint_high_glucose) \\\n",
    "    .trigger(processingTime='5 seconds') \\\n",
    "    .start()\n",
    "\n",
    "\n",
    "query_low_glucose = low_glucose_json_df.writeStream \\\n",
    "    .format(\"eventhubs\") \\\n",
    "    .options(**ehConfigLowGlucose) \\\n",
    "    .option(\"checkpointLocation\", checkpoint_low_glucose) \\\n",
    "    .trigger(processingTime='5 seconds') \\\n",
    "    .start()\n",
    "\n",
    "query_lost_connection = lost_connection_json_df.writeStream \\\n",
    "    .format(\"eventhubs\") \\\n",
    "    .options(**ehConfLostConn) \\\n",
    "    .option(\"checkpointLocation\", checkpoint_lost_connection) \\\n",
    "    .trigger(processingTime='5 seconds') \\\n",
    "    .start()\n",
    "\n",
    "query_transmission_quality = missed_readings_df \\\n",
    "    .writeStream \\\n",
    "    .outputMode(\"append\") \\\n",
    "    .format(\"eventhubs\") \\\n",
    "    .options(**ehConfMS) \\\n",
    "    .option(\"checkpointLocation\", checkpoint_transmission_quality) \\\n",
    "    .trigger(processingTime='5 seconds') \\\n",
    "    .start()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "90fcb471-ddfa-45ea-850e-708586b9360b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# import time\n",
    "\n",
    "# for _ in range(50):  # Number of iterations\n",
    "#     print(query.status)\n",
    "#     spark.sql(\"SELECT * FROM final_table ORDER BY final_df_timestamp DESC LIMIT 20\").display()\n",
    "#     time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ff09d836-c8ee-45cb-b125-091031fb1db8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Uncomment below to stop the queries\n",
    "\n",
    "# query.stop()\n",
    "# query_high_glucose.stop()\n",
    "# query_lost_connection.stop()\n",
    "# query_low_glucose.stop()\n",
    "# query_transmission_quality.stop() "
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Glucose Monitoring Streaming Business Logic",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
